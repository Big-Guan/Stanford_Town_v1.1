/**
 * æ•°æ®åº“å¥åº·æ£€æŸ¥å’Œè‡ªåŠ¨è¿ç§»è„šæœ¬
 * AIè¿›åŒ–å°é•‡ v2.0
 * 
 * åŠŸèƒ½ï¼š
 * 1. æ£€æŸ¥æ•°æ®åº“è¿žæŽ¥
 * 2. éªŒè¯è¡¨ç»“æž„å®Œæ•´æ€§
 * 3. è‡ªåŠ¨æ‰§è¡Œå¿…è¦çš„è¿ç§»
 * 4. è¾“å‡ºå¥åº·æŠ¥å‘Š
 */

import pg from 'pg'
import dotenv from 'dotenv'
import path from 'path'
import { fileURLToPath } from 'url'

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

// ç¡®ä¿ä»Žæ­£ç¡®çš„è·¯å¾„åŠ è½½ .env æ–‡ä»¶
dotenv.config({ path: path.join(__dirname, '.env') })

const { Pool } = pg

const pool = new Pool({
  host: process.env.DB_HOST,
  port: parseInt(process.env.DB_PORT) || 3432,
  database: process.env.DB_NAME,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD,
  ssl: process.env.DB_SSL === 'true' ? { rejectUnauthorized: false } : false,
})

// å®šä¹‰æœŸæœ›çš„æ•°æ®åº“ç»“æž„
const EXPECTED_SCHEMA = {
  users: {
    columns: ['id', 'username', 'email', 'avatar_url', 'created_at', 'updated_at'],
    required: ['id', 'username', 'created_at', 'updated_at']
  },
  user_progress: {
    columns: ['user_id', 'score', 'inventory', 'position', 'avatar', 'completed_npcs', 'level_index', 'updated_at'],
    required: ['user_id', 'score', 'inventory', 'position', 'completed_npcs', 'level_index', 'updated_at']
  },
  task_completions: {
    columns: ['id', 'user_id', 'npc_id', 'task_type', 'submitted_content', 'ai_feedback', 'passed', 'created_at'],
    required: ['id', 'user_id', 'npc_id', 'task_type', 'submitted_content', 'passed', 'created_at']
  }
}

// è¿ç§»è„šæœ¬
const MIGRATIONS = [
  {
    name: 'add_level_index_to_user_progress',
    check: async () => {
      const result = await pool.query(`
        SELECT column_name FROM information_schema.columns 
        WHERE table_name = 'user_progress' AND column_name = 'level_index'
      `)
      return result.rows.length > 0
    },
    up: async () => {
      await pool.query(`
        ALTER TABLE user_progress 
        ADD COLUMN level_index INTEGER DEFAULT 0
      `)
    },
    description: 'æ·»åŠ  level_index å­—æ®µåˆ° user_progress è¡¨'
  },
  {
    name: 'add_avatar_to_user_progress',
    check: async () => {
      const result = await pool.query(`
        SELECT column_name FROM information_schema.columns 
        WHERE table_name = 'user_progress' AND column_name = 'avatar'
      `)
      return result.rows.length > 0
    },
    up: async () => {
      await pool.query(`
        ALTER TABLE user_progress 
        ADD COLUMN avatar TEXT
      `)
    },
    description: 'æ·»åŠ  avatar å­—æ®µåˆ° user_progress è¡¨'
  },
  {
    name: 'add_score_index',
    check: async () => {
      const result = await pool.query(`
        SELECT indexname FROM pg_indexes 
        WHERE tablename = 'user_progress' AND indexname = 'idx_user_progress_score'
      `)
      return result.rows.length > 0
    },
    up: async () => {
      await pool.query(`
        CREATE INDEX IF NOT EXISTS idx_user_progress_score 
        ON user_progress(score DESC)
      `)
    },
    description: 'ä¸º user_progress.score åˆ›å»ºç´¢å¼•ï¼ˆæŽ’è¡Œæ¦œä¼˜åŒ–ï¼‰'
  }
]

async function checkConnection() {
  console.log('\nðŸ”Œ æ£€æŸ¥æ•°æ®åº“è¿žæŽ¥...')
  
  if (!process.env.DB_USER || !process.env.DB_PASSWORD) {
    console.error('âŒ é”™è¯¯: DB_USER æˆ– DB_PASSWORD æœªé…ç½®')
    console.error('   è¯·åœ¨ backend/.env ä¸­é…ç½®æ•°æ®åº“å‡­è¯')
    return false
  }

  try {
    const result = await pool.query('SELECT NOW() as server_time, current_database() as db_name')
    console.log(`âœ… æ•°æ®åº“è¿žæŽ¥æˆåŠŸ`)
    console.log(`   ðŸ“ ä¸»æœº: ${process.env.DB_HOST}:${process.env.DB_PORT}`)
    console.log(`   ðŸ“ æ•°æ®åº“: ${result.rows[0].db_name}`)
    console.log(`   â° æœåŠ¡å™¨æ—¶é—´: ${result.rows[0].server_time}`)
    return true
  } catch (error) {
    console.error(`âŒ æ•°æ®åº“è¿žæŽ¥å¤±è´¥: ${error.message}`)
    return false
  }
}

async function checkTables() {
  console.log('\nðŸ“‹ æ£€æŸ¥æ•°æ®è¡¨...')
  
  const result = await pool.query(`
    SELECT table_name 
    FROM information_schema.tables 
    WHERE table_schema = 'public' AND table_type = 'BASE TABLE'
  `)
  
  const existingTables = result.rows.map(r => r.table_name)
  const requiredTables = Object.keys(EXPECTED_SCHEMA)
  
  let allExist = true
  for (const table of requiredTables) {
    if (existingTables.includes(table)) {
      console.log(`   âœ… ${table}`)
    } else {
      console.log(`   âŒ ${table} (ä¸å­˜åœ¨)`)
      allExist = false
    }
  }
  
  return allExist
}

async function checkTableColumns(tableName) {
  const result = await pool.query(`
    SELECT column_name, data_type, column_default, is_nullable
    FROM information_schema.columns 
    WHERE table_name = $1
    ORDER BY ordinal_position
  `, [tableName])
  
  return result.rows
}

async function checkSchema() {
  console.log('\nðŸ” æ£€æŸ¥è¡¨ç»“æž„...')
  
  const issues = []
  
  for (const [tableName, schema] of Object.entries(EXPECTED_SCHEMA)) {
    const columns = await checkTableColumns(tableName)
    const columnNames = columns.map(c => c.column_name)
    
    console.log(`\n   ðŸ“Š ${tableName}:`)
    
    for (const requiredCol of schema.required) {
      if (columnNames.includes(requiredCol)) {
        const col = columns.find(c => c.column_name === requiredCol)
        console.log(`      âœ… ${requiredCol} (${col.data_type})`)
      } else {
        console.log(`      âŒ ${requiredCol} (ç¼ºå¤±)`)
        issues.push({ table: tableName, column: requiredCol, issue: 'missing' })
      }
    }
    
    // æ£€æŸ¥å¯é€‰å­—æ®µ
    for (const optionalCol of schema.columns.filter(c => !schema.required.includes(c))) {
      if (columnNames.includes(optionalCol)) {
        const col = columns.find(c => c.column_name === optionalCol)
        console.log(`      âœ… ${optionalCol} (${col.data_type}) [å¯é€‰]`)
      } else {
        console.log(`      âš ï¸  ${optionalCol} (å¯é€‰å­—æ®µç¼ºå¤±)`)
      }
    }
  }
  
  return issues
}

async function runMigrations() {
  console.log('\nðŸ”„ æ£€æŸ¥å¹¶æ‰§è¡Œè¿ç§»...')
  
  let migrationsRun = 0
  
  for (const migration of MIGRATIONS) {
    const alreadyApplied = await migration.check()
    
    if (alreadyApplied) {
      console.log(`   âœ… ${migration.name} (å·²å­˜åœ¨)`)
    } else {
      console.log(`   ðŸ”§ æ‰§è¡Œ: ${migration.name}`)
      console.log(`      æè¿°: ${migration.description}`)
      
      try {
        await migration.up()
        console.log(`      âœ… å®Œæˆ`)
        migrationsRun++
      } catch (error) {
        console.log(`      âŒ å¤±è´¥: ${error.message}`)
      }
    }
  }
  
  return migrationsRun
}

async function checkIndexes() {
  console.log('\nðŸ“‡ æ£€æŸ¥ç´¢å¼•...')
  
  const result = await pool.query(`
    SELECT indexname, tablename 
    FROM pg_indexes 
    WHERE schemaname = 'public'
  `)
  
  const expectedIndexes = [
    { name: 'idx_users_username', table: 'users' },
    { name: 'idx_user_progress_score', table: 'user_progress' },
    { name: 'idx_task_completions_user_id', table: 'task_completions' },
    { name: 'idx_task_completions_created_at', table: 'task_completions' },
  ]
  
  for (const idx of expectedIndexes) {
    const exists = result.rows.some(r => r.indexname === idx.name)
    if (exists) {
      console.log(`   âœ… ${idx.name} on ${idx.table}`)
    } else {
      console.log(`   âš ï¸  ${idx.name} on ${idx.table} (ç¼ºå¤±)`)
    }
  }
}

async function getTableStats() {
  console.log('\nðŸ“ˆ æ•°æ®ç»Ÿè®¡...')
  
  const tables = ['users', 'user_progress', 'task_completions']
  
  for (const table of tables) {
    try {
      const result = await pool.query(`SELECT COUNT(*) as count FROM ${table}`)
      console.log(`   ðŸ“Š ${table}: ${result.rows[0].count} æ¡è®°å½•`)
    } catch (error) {
      console.log(`   âŒ ${table}: æŸ¥è¯¢å¤±è´¥`)
    }
  }
}

async function main() {
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
  console.log('       AIè¿›åŒ–å°é•‡ æ•°æ®åº“å¥åº·æ£€æŸ¥ä¸Žè‡ªåŠ¨è¿ç§»')
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
  
  // 1. æ£€æŸ¥è¿žæŽ¥
  const connected = await checkConnection()
  if (!connected) {
    await pool.end()
    process.exit(1)
  }
  
  // 2. æ£€æŸ¥è¡¨
  const tablesOk = await checkTables()
  if (!tablesOk) {
    console.log('\nâš ï¸  è­¦å‘Š: éƒ¨åˆ†è¡¨ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ schema-aliyun.sql åˆå§‹åŒ–æ•°æ®åº“')
    await pool.end()
    process.exit(1)
  }
  
  // 3. æ£€æŸ¥å¹¶æ‰§è¡Œè¿ç§»
  const migrationsRun = await runMigrations()
  
  // 4. æ£€æŸ¥è¡¨ç»“æž„
  const issues = await checkSchema()
  
  // 5. æ£€æŸ¥ç´¢å¼•
  await checkIndexes()
  
  // 6. æ•°æ®ç»Ÿè®¡
  await getTableStats()
  
  // 7. æ€»ç»“æŠ¥å‘Š
  console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
  console.log('                     å¥åº·æ£€æŸ¥æŠ¥å‘Š')
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
  
  if (issues.length === 0 && migrationsRun >= 0) {
    console.log('âœ… æ•°æ®åº“çŠ¶æ€: å¥åº·')
    console.log(`ðŸ“Š æ‰§è¡Œè¿ç§»æ•°: ${migrationsRun}`)
    console.log('ðŸš€ å¯ä»¥å®‰å…¨ä¸Šçº¿ï¼')
  } else {
    console.log('âš ï¸  æ•°æ®åº“çŠ¶æ€: éœ€è¦æ³¨æ„')
    console.log(`âŒ å‘çŽ°é—®é¢˜: ${issues.length} ä¸ª`)
    for (const issue of issues) {
      console.log(`   - ${issue.table}.${issue.column}: ${issue.issue}`)
    }
  }
  
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n')
  
  await pool.end()
}

main().catch(error => {
  console.error('è„šæœ¬æ‰§è¡Œå¤±è´¥:', error)
  process.exit(1)
})

